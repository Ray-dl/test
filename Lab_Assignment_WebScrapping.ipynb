{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment\n",
    "\n",
    "In this lab assignment, you will improve your skills in scraping data from web pages, organizing the data in a desired format. To do so, we will use data that is provided by the Indeed company via their web pages.\n",
    "\n",
    "\n",
    "You task will be to exectute the following blocks of code and try to understand what is happening after each line of the code. You will have to answer several questions to show your understanding.\n",
    "\n",
    "Let us start with importing of the relevant packages.\n",
    "\n",
    "Warning: I am using Python 3 for this lab assignment. If you are using Python 2, then some libraries may need to be changed., e.g., urllib -> urlib2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import urllib.error\n",
    "import bs4 #this is beautiful soup\n",
    "\n",
    "import time\n",
    "from pandas import Series\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, you imported the package called `re`, which supports regular expression operations. You have already used the other packages. \n",
    "\n",
    "The following block will access and load the contents of an Indeed.com web page. It will probably give you a warning -- please ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed url for job postings containing data scientist\n",
    "url = 'https://www.indeed.fr/jobs?q=data+scientist&l=%C3%8Ele-de-France'\n",
    "# read the website\n",
    "source = urllib.request.urlopen(url).read()\n",
    "# parse html code\n",
    "bs_tree = bs4.BeautifulSoup(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Question 1**:\n",
    " * What kind of page did you land on? Explain in a few sentences what is the content of this page.\n",
    " * What does the \"?\" and \"&\" in the url mean?\n",
    " * Explore the content of the web page. If you are using Firefox, open the page Inspector to understand how the underlying html code relates to the displayed content.\n",
    " * What pieces of the html code are responsible for showing the job title, company name, and job location?\n",
    " \n",
    "The following block of code will figure out how many job ads are there for jobs that contain \"data scientist' in the job title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how many job postings we found\n",
    "job_count_string = bs_tree.find(id = 'searchCountPages').contents[0]\n",
    "job_count_string = job_count_string.split()[-2]\n",
    "print((\"Search yielded %s hits.\" % (job_count_string)))\n",
    "\n",
    "# not that job_count so far is still a string, \n",
    "# not an integer, and the , separator prevents \n",
    "# us from just casting it to int\n",
    "\n",
    "job_count_digits = [int(d) for d in job_count_string if d.isdigit()]\n",
    "job_count = np.sum([digit*(10**exponent) for digit, exponent in \n",
    "                    zip(job_count_digits[::-1], list(range(len(job_count_digits))))])\n",
    "\n",
    "print(job_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Question 2**:\n",
    "* What does the \"find(id = 'searchCountPages')\" in the first line mean?\n",
    "* What does the second line do?\n",
    "\n",
    "**Question 3**: \n",
    "* Write a piece of code that finds the Salary Estimate object on the page\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following piece of code allows you to find the links to all the job ads on the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The website is only listing 10 results per page, \n",
    "# so we need to scrape them page after page\n",
    "num_pages = int(np.ceil(job_count/10.0))\n",
    "\n",
    "base_url = 'http://www.indeed.com'\n",
    "job_links = []\n",
    "for i in range(2): #do range(num_pages) if you want them all\n",
    "    url = 'https://www.indeed.fr/emplois?q=data+scientist&l=%C3%8Ele-de-France&start=' + str(i*10)\n",
    "    html_page = urllib.request.urlopen(url).read() \n",
    "    bs_tree = bs4.BeautifulSoup(html_page)\n",
    "    job_link_area = bs_tree.find(id = 'resultsCol')\n",
    "\n",
    "    job_postings = job_link_area.findAll(\"div\")\n",
    "    job_postings = [jp for jp in job_postings if str(jp.get('class')).find('row result')]\n",
    "    \n",
    "    job_ids = [jp.get('data-jk') for jp in job_postings]\n",
    "    \n",
    "    \n",
    "    # go after each link\n",
    "    for id in job_ids:\n",
    "        if (id != None):\n",
    "            job_links.append(base_url + '/rc/clk?jk=' + id)\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"We found a lot of jobs: \", len(job_links))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**:\n",
    "* explain why is `url` (first line in the for loop) defined as it is. What page are you landing at when `i = 3`?\n",
    "* What does command `bs_tree.find(id = 'resultsCol')` do?\n",
    "* What does command `''.join(jp.get('class'))` do?\n",
    "* Explain the properties and content of `job_links`\n",
    "\n",
    "**Question 5**:\n",
    "* Reuse the code above to find links to the first 200 listed data science jobs\n",
    "\n",
    "The following piece of code accesses and grabs the content of all ads in the `job_links` and extracts all the human-readable text tokens. Then, it counts on how many pages are words `mapreduce`, `spark`, and `visualization` used. It might take a few seconds to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_set = {'hadoop':0, 'spark':0, 'python':0}\n",
    "counter = 0\n",
    "for link in job_links:\n",
    "    counter +=1  \n",
    "    \n",
    "    try:\n",
    "        html_page = urllib.request.urlopen(link).read()\n",
    "    except urllib.error.HTTPError:\n",
    "        continue\n",
    "    except urllib.error.URLError:\n",
    "        continue\n",
    "    except socket.error as error:\n",
    "        print(\"Connection closed\")\n",
    "        continue\n",
    "\n",
    "    html_text = re.sub(\"[^a-z.+3]\",\" \", html_page.decode('utf-8').lower()) # replace all but the listed characters\n",
    "    \n",
    "        \n",
    "    for key in list(skill_set.keys()):\n",
    "        if key in html_text:  \n",
    "            skill_set[key] +=1\n",
    "            \n",
    "    if counter % 5 == 0:\n",
    "        print(len(job_links) - counter)\n",
    "        print(skill_set)\n",
    "            \n",
    "print(skill_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Question 6**\n",
    "* What does the `re.sub()` do in the above code? To answer this, you will have to go to the documentation of the regular expression package (find it on web).\n",
    "* What is the meaning of `[^a-z.+3]`?\n",
    "* What is the content of `skill_set`?\n",
    "\n",
    "The following piece of code plots the counts of different skills in the processed ads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseries = pd.Series(skill_set)\n",
    "pseries.sort_values(ascending=False)\n",
    "\n",
    "pseries.plot(kind = 'bar')\n",
    "## set the title to Score Comparison\n",
    "plt.title('Data Science Skills')\n",
    "## set the x label\n",
    "plt.xlabel('Skills')\n",
    "## set the y label\n",
    "plt.ylabel('Count')\n",
    "## show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7**:\n",
    "- rerun the code to find the counts of the 3 data science skills on the first 200 job ads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data analysis of the housing market in the Paris area \n",
    "\n",
    "In the first part of the lab, you created `skill_set` dictionary that counts occurences of 3 important data science skills of the jobs in Ile de France. In the second part of this lab, your task will be to create a padas 'DataFrame' object containing information about the flats/houses that are available for rent in the paris area. For each offer, you will have to create columns such as: \n",
    "- Location\n",
    "- Surface\n",
    "- Number of rooms\n",
    "- ...\n",
    "\n",
    "To do so, we will be using seloger.com. Unlike the first part, where you were provided with snippets of codes that help you get familiarized with Web Scrapping skills, in this part you are left on your own to figure out how to do so. You can reduce your search to a specific area of paris, e.g., Paris 9, and for specific range of rent [700 euros,800 euros].\n",
    "\n",
    "https://www.seloger.com/list.htm?projects=1&types=1,2&places=[{div:2238}]&price=700/800&enterprise=0&qsVersion=1.0\n",
    "\n",
    "Note: I obtained the above URL by simply using the web page as a human via a browser, and specifying the criteria I needed to via the web form provided by seloger.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Deliverable: the modified .ipynb file that contains the answers to the questions"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
